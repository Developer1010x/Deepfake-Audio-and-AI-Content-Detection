from flask import Flask, render_template, request, redirect, url_for
from werkzeug.utils import secure_filename
import os
import numpy as np
import librosa
from tensorflow.keras.models import load_model
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import torch.nn.functional as F

app = Flask(__name__)

# Configuration for audio processing
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['ALLOWED_EXTENSIONS'] = {'wav', 'mp3', 'flac'}
MODEL_PATH = 'Deepfake_audio.h5'
SAMPLE_RATE = 16000
DURATION = 5
N_MELS = 128
MAX_TIME_STEPS = 109

# Load models
audio_model = load_model(MODEL_PATH)
text_model = BertForSequenceClassification.from_pretrained("model")
text_tokenizer = BertTokenizer.from_pretrained("model")

# Move text model to the device (CPU/GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
text_model.to(device)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def preprocess_audio(file_path):
    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)
    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)
    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)
    if mel_spectrogram.shape[1] < MAX_TIME_STEPS:
        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, MAX_TIME_STEPS - mel_spectrogram.shape[1])), mode='constant')
    else:
        mel_spectrogram = mel_spectrogram[:, :MAX_TIME_STEPS]
    return np.expand_dims(mel_spectrogram, axis=0)

def predict_text(text):
    inputs = text_tokenizer(text, padding=True, truncation=True, return_tensors='pt', max_length=128)
    inputs = {key: value.to(device) for key, value in inputs.items()}
    with torch.no_grad():
        outputs = text_model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1)
    return probs[0][1].item() * 100  # Probability of AI-generated text in percentage

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return redirect(request.url)
    file = request.files['file']
    if file.filename == '':
        return redirect(request.url)
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)
        X_test = preprocess_audio(file_path)
        y_pred = audio_model.predict(X_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        prediction = y_pred_classes[0]
        result = "Real Audio" if prediction == 1 else "Deepfake Audio"
        return render_template('result.html', prediction=result, task='audio')
    return redirect(request.url)

@app.route("/text", methods=["POST"])
def analyze_text():
    user_input = request.form["text"]
    if user_input.strip() != "":
        probability = predict_text(user_input)
        if probability > 50.0:
            result = f"Not generated by AI with a probability of {probability:.2f}%"
        else:
            human_probability = 100 - probability
            result = f"AI generated with a probability of {human_probability:.2f}%"
    else:
        result = "Please enter some text to analyze."
    return render_template("result.html", result=result, task='text', user_input=user_input)

if __name__ == '__main__':
    if not os.path.exists(app.config['UPLOAD_FOLDER']):
        os.makedirs(app.config['UPLOAD_FOLDER'])
    app.run(debug=True)
